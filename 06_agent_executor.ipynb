{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzN7iY0FLRxn"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aurelio-labs/langchain-course/blob/main/chapters/06-agent-executor.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-WuDI4tKhRz"
      },
      "source": [
        "#### LangChain Essentials Course"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_bfadwMKhR0"
      },
      "source": [
        "# LangChain Agent Executor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMGT85HYKhR0"
      },
      "source": [
        "In this chapter, we will continue from the [introduction to agents](https://aurelio.ai/learn/langchain-agents-intro) and dive deeper into agents. Learning how to build our custom agent execution loop for v0.3 of LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWpBTKoHKj9o",
        "outputId": "68fc986f-ae96-4d3e-c82b-369cb711a527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 0.3.27\n",
            "Uninstalling langchain-0.3.27:\n",
            "  Successfully uninstalled langchain-0.3.27\n",
            "Found existing installation: google-generativeai 0.8.5\n",
            "Uninstalling google-generativeai-0.8.5:\n",
            "  Successfully uninstalled google-generativeai-0.8.5\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.7/241.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.8/378.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y langchain google-generativeai\n",
        "!pip install -qU \\\n",
        "  \"pydantic>=2.11.4,<3\" \\\n",
        "  \"langchain-core>=0.3.70,<0.4\" \\\n",
        "  \"langchain-community>=0.3.27,<0.4\" \\\n",
        "  \"langchain-google-genai>=2.1.10\" \\\n",
        "  \"google-genai>=0.7.0\" \\\n",
        "  \"langsmith>=0.3.4\" \\\n",
        "  google-search-results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPxtmAUnKhR0"
      },
      "source": [
        "---\n",
        "\n",
        "> ⚠️ If using LangSmith, add your API key below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vu3UjJZcKhR1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "# must enter API key\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\") or \\\n",
        "    getpass(\"Enter LangSmith API Key: \")\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"aurelioai-langchain-course-agent-executor-openai\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIWrsEZLKhR1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nN4iokHKhR1"
      },
      "source": [
        "## What is the Agent Executor?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgYiaDvQKhR1"
      },
      "source": [
        "When we talk about agents, a significant part of an \"agent\" is simple code logic,\n",
        "iteratively rerunning LLM calls and processing their output. The exact logic varies\n",
        "significantly, but one well-known example is the **ReAct** agent.\n",
        "\n",
        "![ReAct process](https://www.aurelio.ai/_next/image?url=%2Fimages%2Fposts%2Fai-agents%2Fai-agents-00.png&w=640&q=75)\n",
        "\n",
        "**Re**ason + **Act**ion (ReAct) agents use iterative _reasoning_ and _action_ steps to\n",
        "incorporate chain-of-thought and tool-use into their execution. During the _reasoning_\n",
        "step, the LLM generates the steps to take to answer the query. Next, the LLM generates\n",
        "the _action_ input, which our code logic parses into a tool call.\n",
        "\n",
        "![Agentic graph of ReAct](https://www.aurelio.ai/_next/image?url=%2Fimages%2Fposts%2Fai-agents%2Fai-agents-01.png&w=640&q=75)\n",
        "\n",
        "Following our action step, we get an observation from the tool call. Then, we feed the\n",
        "observation back into the agent executor logic for a final answer or further reasoning\n",
        "and action steps.\n",
        "\n",
        "The agent and agent executor we will be building will follow this pattern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y9epAuyKhR1"
      },
      "source": [
        "## Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNwxnS9qKhR1"
      },
      "source": [
        "As with the previous chapter, we will define a few tools to use within our agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t0xbHzHqKhR2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def add(x: float, y: float) -> float:\n",
        "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
        "    return x + y\n",
        "\n",
        "# Define the multiply tool\n",
        "@tool\n",
        "def multiply(x: float, y: float) -> float:\n",
        "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
        "    return x * y\n",
        "\n",
        "# Define the exponentiate tool\n",
        "@tool\n",
        "def exponentiate(x: float, y: float) -> float:\n",
        "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
        "    return x ** y\n",
        "\n",
        "@tool\n",
        "def subtract(x: float, y: float) -> float:\n",
        "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
        "    return y - x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhlrt2JfKhR2"
      },
      "source": [
        "With the `@tool` decorator our function is turned into a `StructuredTool` object, which we can see below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLGsdWrCKhR2",
        "outputId": "bbf3991f-074c-4119-f544-bba45e1bd944"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x7910d4f23c40>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "add"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JRtoCoQKhR2"
      },
      "source": [
        "We can see the tool name, description, and arg schema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjbUg5JGKhR2",
        "outputId": "edc167b7-3002-43cf-9892-3acd014d8d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "add.name='add'\n",
            "add.description=\"Add 'x' and 'y'.\"\n"
          ]
        }
      ],
      "source": [
        "print(f\"{add.name=}\\n{add.description=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akWPmNfhKhR2",
        "outputId": "195abb58-7522-46a5-f307-9c598c7433cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'description': \"Add 'x' and 'y'.\",\n",
              " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
              "  'y': {'title': 'Y', 'type': 'number'}},\n",
              " 'required': ['x', 'y'],\n",
              " 'title': 'add',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "add.args_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INJu45q1KhR2"
      },
      "source": [
        "The `args_schema` is a pydantic model that is transformed into the JSON schema above and passed into our LLM, it is this that defines _how_ the tool is used for the LLM. We can see this with other tools:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYdKvlunKhR2",
        "outputId": "d64cf30f-ea16-4ac3-d2e3-f61ff62c1f4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'description': \"Raise 'x' to the power of 'y'.\",\n",
              " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
              "  'y': {'title': 'Y', 'type': 'number'}},\n",
              " 'required': ['x', 'y'],\n",
              " 'title': 'exponentiate',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "exponentiate.args_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlqrsBLSKhR2"
      },
      "source": [
        "When invoking the tool, a JSON string output by the LLM will be parsed into JSON and then consumed as kwargs, similar to the below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qs-a16-KhR2",
        "outputId": "52678ca6-7535-41d3-cd7a-dadbc7ad54cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': 5, 'y': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"  # this is the output from the LLM\n",
        "llm_output_dict = json.loads(llm_output_string)  # load as dictionary\n",
        "llm_output_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgwHOKetKhR2"
      },
      "source": [
        "This is then passed into the tool function as `kwargs` (keyword arguments) as indicated by the `**` operator - the `**` operator is used to unpack the dictionary into keyword arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIEsWEANKhR2",
        "outputId": "694f6412-119e-4846-8c2a-9336a461b969"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "exponentiate.func(**llm_output_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leNf7-zuKhR3"
      },
      "source": [
        "This covers the basics of tools and how they work, let's move on to creating the agent itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLzr9H4HKhR3"
      },
      "source": [
        "## Creating an Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wshUd8OLKhR3"
      },
      "source": [
        "We will use **L**ang**C**hain **E**pression **L**anguage (LCEL) to construct the agent. We will cover LCEL more in the next chapter, but for now - all we need to know is that our agent will be constructed using syntax and components like so:\n",
        "\n",
        "\n",
        "```\n",
        "agent = (\n",
        "    <input parameters, including chat history and user query>\n",
        "    | <prompt>\n",
        "    | <LLM with tools>\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcXrDNP5KhR3"
      },
      "source": [
        "We need this agent to remember previous interactions within the conversation. To do that, we will use the `ChatPromptTemplate` with a system message, a placeholder for our chat history, a placeholder for the user query, and finally a placeholder for the agent scratchpad.\n",
        "\n",
        "The agent scratchpad is where the agent writes its notes as it works through multiple internal thought and tool-use steps to produce a final output for the user. This scratchpad is a list of messages with alternating roles of `ai` (for the tool call) and `tool` (for the tool execution output). Both message types require a `tool_call_id` field which is used to link the respective AI and tool messages - this can be required when we many tool calls happening in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "deEyRB1qKhR3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", (\n",
        "        \"You're a helpful assistant. When answering a user's question \"\n",
        "        \"you should first use one of the tools provided. After using a \"\n",
        "        \"tool the tool output will be provided in the \"\n",
        "        \"'scratchpad' below. If you have an answer in the \"\n",
        "        \"scratchpad you should not use any more tools and \"\n",
        "        \"instead answer directly to the user.\"\n",
        "    )),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qLBd6IKKhR3"
      },
      "source": [
        "Next, we must define our LLM, we will use the `gpt-4o-mini` model with a `temperature` of `0.0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "taeBT2ppKhR3"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\") or getpass(\n",
        "    \"Enter Gemini API Key: \"\n",
        ")\n",
        "\n",
        "openai_model = \"gemini-1.5-flash\"\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=openai_model,\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kIxpYSWKhR3"
      },
      "source": [
        "To add tools to our LLM, we will use the `bind_tools` method within the LCEL constructor, which will take our tools and add them to the LLM. We'll also include the `tool_choice=\"any\"` argument to `bind_tools`, which tells the LLM that it _MUST_ use a tool, ie it cannot provide a final answer directly (in therefore not using a tool):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "yFWmJdoVKhR3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables.base import RunnableSerializable\n",
        "\n",
        "tools = [add, subtract, multiply, exponentiate]\n",
        "\n",
        "# define the agent runnable\n",
        "agent: RunnableSerializable = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
        "    }\n",
        "    | prompt\n",
        "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xvYJGV2KhR3"
      },
      "source": [
        "We invoke the agent with the `invoke` method, passing in the input and chat history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0Wy32aKKhR4",
        "outputId": "f910b2bd-a284-424c-e428-ac4483345b67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"y\": 10.0, \"x\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--6547257f-2074-4af0-b16c-5e213cd80a1b-0', tool_calls=[{'name': 'add', 'args': {'y': 10.0, 'x': 10.0}, 'id': '78324174-aa20-48d0-9962-01202aa36f94', 'type': 'tool_call'}], usage_metadata={'input_tokens': 145, 'output_tokens': 5, 'total_tokens': 150, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
        "tool_call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKLcAncRKhR4"
      },
      "source": [
        "Because we set `tool_choice=\"any\"` to force the tool output, the usual `content` field will be empty as that field is used for natural language output, ie the _final answer_ of the LLM. To find our tool output, we need to look at the `tool_calls` field:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnwf4bZyKhR4",
        "outputId": "39eb67c8-d22e-4def-c8cb-31f43ec088b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'add',\n",
              "  'args': {'y': 10.0, 'x': 10.0},\n",
              "  'id': '78324174-aa20-48d0-9962-01202aa36f94',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "tool_call.tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK3aEExCKhR4"
      },
      "source": [
        "From here, we have the tool `name` that our LLM wants to use and the `args` that it\n",
        "wants to pass to that tool. We can see that the tool `add` is being used with the\n",
        "arguments `x=10` and `y=10`. The `agent.invoke` method has _not_ executed the tool\n",
        "function; we need to write that part of the agent code ourselves.\n",
        "\n",
        "Executing the tool code requires two steps:\n",
        "\n",
        "1. Map the tool `name` to the tool function.\n",
        "\n",
        "2. Execute the tool function with the generated `args`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "IJ9MNrsmKhR4"
      },
      "outputs": [],
      "source": [
        "# create tool name to function mapping\n",
        "name2tool = {tool.name: tool.func for tool in tools}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2olPmt13KhR4"
      },
      "source": [
        "Now execute to get our answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clu5QfGzKhR4",
        "outputId": "1cf672e2-6f7a-4884-d55c-c68f81ccdd84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
        "    **tool_call.tool_calls[0][\"args\"]\n",
        ")\n",
        "tool_exec_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKs1H38BKhR4"
      },
      "source": [
        "That is our answer and tool execution logic. We feed this back into our LLM via the\n",
        "`agent_scratchpad` placeholder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taboyGD1KhR4",
        "outputId": "b86176e6-9059-4d93-bba7-3de894c0e99d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"y\": 10.0, \"x\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--945fb39f-2f87-4d17-a1c2-d334fbad5291-0', tool_calls=[{'name': 'add', 'args': {'y': 10.0, 'x': 10.0}, 'id': '2a20ce5c-2b0e-414d-b18c-3f12f7e0e422', 'type': 'tool_call'}], usage_metadata={'input_tokens': 161, 'output_tokens': 5, 'total_tokens': 166, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "tool_exec = ToolMessage(\n",
        "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_exec_content}\",\n",
        "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
        ")\n",
        "\n",
        "out = agent.invoke({\n",
        "    \"input\": \"What is 10 + 10\",\n",
        "    \"chat_history\": [],\n",
        "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
        "})\n",
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Skkn6MKhR4"
      },
      "source": [
        "Despite having the answer in our `agent_scratchpad`, the LLM still tries to use the tool\n",
        "_again_. This behaviour happens because we bonded the tools to the LLM with\n",
        "`tool_choice=\"any\"`. When we set `tool_choice` to `\"any\"` or `\"required\"`, we tell the\n",
        "LLM that it _MUST_ use a tool, i.e., it cannot provide a final answer.\n",
        "\n",
        "There's two options to fix this:\n",
        "\n",
        "1. Set `tool_choice=\"auto\"` to tell the LLM that it can choose to use a tool or provide\n",
        "a final answer.\n",
        "\n",
        "2. Create a `final_answer` tool - we'll explain this shortly.\n",
        "\n",
        "First, let's try option **1**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "RzxJcsTiKhR5"
      },
      "outputs": [],
      "source": [
        "agent: RunnableSerializable = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
        "    }\n",
        "    | prompt\n",
        "    | llm.bind_tools(tools, tool_choice=\"auto\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShUXAXN2KhR5"
      },
      "source": [
        "We'll start from the start again, so `agent_scratchpad` is empty:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEa-xx4oKhR5",
        "outputId": "efef04be-ada7-448f-9c31-522b57fde7c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"y\": 10.0, \"x\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--7872df64-e3f3-48eb-9eb8-caa4e39f4d0b-0', tool_calls=[{'name': 'add', 'args': {'y': 10.0, 'x': 10.0}, 'id': 'c37c4517-d9fd-45e6-99d4-d884c5fa42c9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 145, 'output_tokens': 5, 'total_tokens': 150, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
        "tool_call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKg7tre5KhR5"
      },
      "source": [
        "Now we execute the tool and pass it's output into the `agent_scratchpad` placeholder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sby4NpDqKhR5",
        "outputId": "d80476a5-bd6a-4177-9fd1-09a616d82f55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='20.0', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--f7fc2a0f-940f-4142-81ff-8f22819b5116-0', usage_metadata={'input_tokens': 161, 'output_tokens': 5, 'total_tokens': 166, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "tool_output = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
        "    **tool_call.tool_calls[0][\"args\"]\n",
        ")\n",
        "tool_exec = ToolMessage(\n",
        "    name=tool_call.tool_calls[0]['name'],\n",
        "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_exec_content}\",\n",
        "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
        ")\n",
        "out = agent.invoke({\n",
        "    \"input\": \"What is 10 + 10\",\n",
        "    \"chat_history\": [],\n",
        "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
        "})\n",
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBfI6-lTKhR5"
      },
      "source": [
        "We now have the final answer in the `content` field! This method is perfectly\n",
        "functional; however, we recommend option **2** as it provides more control over the\n",
        "agent's output.\n",
        "\n",
        "There are several reasons that option **2** can provide more control, those are:\n",
        "\n",
        "* It removes the possibility of an agent using the direct `content` field when it is not\n",
        "appropriate; for example, some LLMs (particularly smaller ones) may try to use the\n",
        "`content` field when using a tool.\n",
        "\n",
        "* We can enforce a specific structured output in our answers. Structured outputs are\n",
        "handy when we require particular fields for downstream code or multi-part answers. For\n",
        "example, a RAG agent may return a natural language answer and a list of sources used to\n",
        "generate that answer.\n",
        "\n",
        "To implement option **2**, we must create a `final_answer` tool. We will add a\n",
        "`tools_used` field to give our output some structure—in a real-world use case, we\n",
        "probably wouldn't want to generate this field, but it's useful for our example here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "4oE3gE3HKhR5"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
        "    \"\"\"Use this tool to provide a final answer to the user.\n",
        "    The answer should be in natural language as this will be provided\n",
        "    to the user directly. The tools_used must include a list of tool\n",
        "    names that were used within the `scratchpad`.\n",
        "    \"\"\"\n",
        "    return {\"answer\": answer, \"tools_used\": tools_used}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AasMBkNjKhR5"
      },
      "source": [
        "Our `final_answer` tool _doesn't_ necessarily need to do anything; in this example,\n",
        "we're using it purely to structure our final response. We can now add this tool to our\n",
        "agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "IiFdJBeyKhR5"
      },
      "outputs": [],
      "source": [
        "tools = [final_answer, add, subtract, multiply, exponentiate]\n",
        "\n",
        "# we need to update our name2tool mapping too\n",
        "name2tool = {tool.name: tool.func for tool in tools}\n",
        "\n",
        "agent: RunnableSerializable = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
        "    }\n",
        "    | prompt\n",
        "    | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEp3rk5XKhR5"
      },
      "source": [
        "Now we invoke:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W0zZLKdKhR5",
        "outputId": "2c0f0ea5-558a-4ead-c143-b8b9d3c0805f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'add',\n",
              "  'args': {'y': 10.0, 'x': 10.0},\n",
              "  'id': '7147c7eb-fd10-44cc-9240-7001ef75603a',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
        "tool_call.tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPAhRRExKhR5"
      },
      "source": [
        "We execute the tool and provide it's output to the agent again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATQh7UevKhR5",
        "outputId": "4ad119f9-bd88-4baf-add6-5d5f4bccb46f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'final_answer', 'arguments': '{\"answer\": \"10 + 10 = 20\", \"tools_used\": [\"add\"]}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--6af05264-e935-4316-bdfb-bf7c6756f4f7-0', tool_calls=[{'name': 'final_answer', 'args': {'answer': '10 + 10 = 20', 'tools_used': ['add']}, 'id': '59769264-cc2c-4064-9bf7-a8806cce829d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 231, 'output_tokens': 18, 'total_tokens': 249, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "tool_out = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
        "    **tool_call.tool_calls[0][\"args\"]\n",
        ")\n",
        "\n",
        "tool_exec = ToolMessage(\n",
        "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_out}\",\n",
        "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
        ")\n",
        "\n",
        "out = agent.invoke({\n",
        "    \"input\": \"What is 10 + 10\",\n",
        "    \"chat_history\": [],\n",
        "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
        "})\n",
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQSd_50BKhR6"
      },
      "source": [
        "We see that `content` remains empty because we force tool use. But we now have the\n",
        "`final_answer` tool, which the agent executor passes via the `tool_calls` field:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwufhIudKhR6",
        "outputId": "ae4ec1c6-23a0-4777-f9f1-66fa917afb3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'final_answer',\n",
              "  'args': {'answer': '10 + 10 = 20', 'tools_used': ['add']},\n",
              "  'id': '59769264-cc2c-4064-9bf7-a8806cce829d',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "out.tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB02HOTZKhR6"
      },
      "source": [
        "Because we see the `final_answer` tool here, we don't pass this back into our agent, and\n",
        "instead, this tells us to stop execution and pass the `args` output onto our downstream\n",
        "process or user directly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQYeqO7fKhR6",
        "outputId": "ae070ea4-1aea-49ce-e280-fc0c5121ccc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': '10 + 10 = 20', 'tools_used': ['add']}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "out.tool_calls[0][\"args\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG4WMRU0KhR6"
      },
      "source": [
        "### Building a Custom Agent Execution Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPMQv0zkKhR6"
      },
      "source": [
        "We've worked through each step of our agent code, but it doesn't run without us running\n",
        "every step. We must write a class to handle all the logic we just worked through."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "cUNR2aDaKhR6"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "\n",
        "\n",
        "class CustomAgentExecutor:\n",
        "    chat_history: list[BaseMessage]\n",
        "\n",
        "    def __init__(self, max_iterations: int = 3):\n",
        "        self.chat_history = []\n",
        "        self.max_iterations = max_iterations\n",
        "        self.agent: RunnableSerializable = (\n",
        "            {\n",
        "                \"input\": lambda x: x[\"input\"],\n",
        "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "                \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
        "            }\n",
        "            | prompt\n",
        "            | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
        "        )\n",
        "\n",
        "    def invoke(self, input: str) -> dict:\n",
        "        # invoke the agent but we do this iteratively in a loop until\n",
        "        # reaching a final answer\n",
        "        count = 0\n",
        "        agent_scratchpad = []\n",
        "        while count < self.max_iterations:\n",
        "            # invoke a step for the agent to generate a tool call\n",
        "            tool_call = self.agent.invoke({\n",
        "                \"input\": input,\n",
        "                \"chat_history\": self.chat_history,\n",
        "                \"agent_scratchpad\": agent_scratchpad\n",
        "            })\n",
        "            # add initial tool call to scratchpad\n",
        "            agent_scratchpad.append(tool_call)\n",
        "            # otherwise we execute the tool and add it's output to the agent scratchpad\n",
        "            tool_name = tool_call.tool_calls[0][\"name\"]\n",
        "            tool_args = tool_call.tool_calls[0][\"args\"]\n",
        "            tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
        "            tool_out = name2tool[tool_name](**tool_args)\n",
        "            # add the tool output to the agent scratchpad\n",
        "            tool_exec = ToolMessage(\n",
        "                content=f\"{tool_out}\",\n",
        "                tool_call_id=tool_call_id\n",
        "            )\n",
        "            agent_scratchpad.append(tool_exec)\n",
        "            # add a print so we can see intermediate steps\n",
        "            print(f\"{count}: {tool_name}({tool_args})\")\n",
        "            count += 1\n",
        "            # if the tool call is the final answer tool, we stop\n",
        "            if tool_name == \"final_answer\":\n",
        "                break\n",
        "        # add the final output to the chat history\n",
        "        final_answer = tool_out[\"answer\"]\n",
        "        self.chat_history.extend([\n",
        "            HumanMessage(content=input),\n",
        "            AIMessage(content=final_answer)\n",
        "        ])\n",
        "        # return the final answer in dict form\n",
        "        return json.dumps(tool_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyaL_PRtKhR6"
      },
      "source": [
        "Now initialize the agent executor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "fopGp7hvKhR6"
      },
      "outputs": [],
      "source": [
        "agent_executor = CustomAgentExecutor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi8oX3lkKhR6"
      },
      "source": [
        "And test the `invoke` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "E3iWRWyFKhR6",
        "outputId": "132d68f8-500a-41a8-b693-e1e95af76648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: add({'y': 5.0, 'x': 10.0})\n",
            "1: final_answer({'answer': '10 + 5 = 15', 'tools_used': ['add']})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"answer\": \"10 + 5 = 15\", \"tools_used\": [\"add\"]}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "agent_executor.invoke(input=\"What is 10 + 5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1nIQpA2KhR6"
      },
      "source": [
        "We then get our answer and the tools that were used — all through our custom agent\n",
        "executor."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}